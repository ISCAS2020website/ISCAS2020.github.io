<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=960">
<title>ISCAS2020 Semantic Layer-Aware Low-Light Enhancement</title>
<link rel="stylesheet" type="text/css" href="css/site.20180920212709.css">
<!--[if lte IE 7]>
<link rel="stylesheet" type="text/css" href="css/site.20180920212709-lteIE7.css">
<![endif]-->
</head>
<body id="body">
<div class="pos vis section">
<div class="vis-2 pos-2 size cont">
<p class="para"><span class="font">Semantic Layer-Aware Low-Light Enhancement</span></p>
</div>
<div class="vis-2 pos-9 size-5 cont-2">
<div class="vis-2 pos-4 size-5 colwrapper">
<div class="vis-2 pos-4 size-6 cont-8">
<picture class="img-2">
<source srcset="images/Fig1.jpg">
<img src="images/Fig1.jpg" alt="" class="js img-2">
</picture>
</div>
<p class="para-4"><span class="font-3">&nbsp;</span></p>
<p class="para-4"><span class="font-3">&nbsp;</span></p>
<div class="vis-2 pos-10 size-7 cont-9">
<p class="para-4"><span class="font-3">Figure 1:Framework of the proposed layer-aware Retinex model. The network first decompose the input image to its Reflectance, Illumination and Semantic-Layer. Then the components are feed into a following network, where they are divided into three separate branches and processed by the parallel models.</span></p>
</div>
</div>
</div>

<div class="vis-2 pos-11 size-8 cont">
<p class="para-5"><span class="font-6">Abstract</span></p>
<p class="para-4"><span class="font-3">Retinex model is widely adopted in various low-light image enhancement tasks, in which a given image is decomposed into its reflectance and illumination. While the ill-posed decomposition is usually handled by hand-crafted constraints and parameters, deep-learning based approaches have been explored these years. In this paper, we extend the idea of basic decomposition that ignores the latent semantic information. We extract the segmentation layer as well as the reflectance and illumination. Based on the observation that various objects and backgrounds have different material, reflection and perspective attributes, regions of a single low-light image may require different  adjustment and enhancement regarding contrast, illumination and noise. We propose an enhancement pipeline with three parts which effectively utilize the semantic layer information. We concurrently enhance separate regions of a low-light image, namely sky, ground and objects for outdoor scenes. We conduct extensive experiments on both synthetic data and real world images, and  demonstrate the superiority of our method over current state-of-the-art low-light enhancement algorithms.</span></p>
<p class="para-4"><span class="font-3">&nbsp;</span></p>
<p class="para-5"><span class="font-6">Objective Results</span><span class="font-3">&nbsp;</span></p>

<picture class="img-2">
<source srcset="images/Table1.jpg">
<img src="images/Table1.jpg" alt="" class="js img-2">
</picture>
<p class="para-4"><span class="font-3">&nbsp;</span></p>
<picture class="img-2">
<source srcset="images/Table2.jpg">
<img src="images/Table2.jpg" alt="" class="js img-2">
</picture>
<p class="para-4"><span class="font-3">&nbsp;</span></p>
<picture class="img-2">
<source srcset="images/Table3.jpg">
<img src="images/Table3.jpg" alt="" class="js img-2">
</picture>
</div>

<div class="vis-2 pos-11 size-1 cont">
<p class="para-5"><span class="font-6">Subjective Results</span><span class="font-3">&nbsp;</span></p>
</div>

<div class="vis-2 pos-11 size-6 cont">
<picture class="img-2">
<source srcset="images/Fig3.jpg">
<img src="images/Fig3.jpg" alt="" class="js img-2">
</picture>
</div>

<div class="vis-2 pos-14 size-16 cont-13">
<p class="para-5"><span class="font-6">Download Links</span><span class="font-3">&nbsp;</span></p>
<ul class="pos-21">
<li class="para-6"><span class="font-7">&bull; </span><span class="font-7">Datasets</span></li>
</ul>
<!--
<p class="para-4"><span class="font-3">&nbsp;&nbsp;&nbsp;&nbsp;Synthetic Image Pairs: </span><span class="font-4"><a href="https://drive.google.com/open?id=1G6fi9Kiu7CDnW2Sh7UQ5ikvScRv8Q14F">Google Drive</a></span><span class="font-3">, </span><span class="font-4"><a href="https://pan.baidu.com/s/1drsMAkRMlwd9vObAM_9Iog">Baidu Pan</a></span></p>
<p class="para-4"><span class="font-3">&nbsp;&nbsp;&nbsp;&nbsp;Testing Images: </span><span class="font-4"><a href="https://drive.google.com/open?id=1OvHuzPBZRBMDWV5AKI-TtIxPCYY8EW70">Google Drive</a></span><span class="font-3">, </span><span class="font-4"><a href="https://pan.baidu.com/s/1G2qg3oS12MmP8_dFlVRRug">Baidu Pan</a></span></p>
-->
<ul class="pos-21">
<li class="para-6"><span class="font-7">&bull; </span><span class="font-7">Codes</span></li>
</ul>
<!-- <p class="para-4"><span class="font-3">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font-4"><a href="https://github.com/weichen582/RetinexNet">Github</a></span></p> -->
<p class="para-4"><span class="font-3">&nbsp;</span></p>

<p class="para-5"><span class="font-6">References</span></p>
<!--
<p class="para-4"><span class="font-3">[1] Xuan Dong, Guan Wang, Yi Pang, Weixin Li, Jiangtao Wen, Wei Meng, and Yao Lu. Fast efficient algorithm for enhancement of low lighting video. In IEEE International Conference on Multimedia and Expo, pages 1&ndash;6, 2011.</span></p>
<p class="para-4"><span class="font-3">[2] Shuhang Wang, Jin Zheng, Hai Miao Hu, and Bo Li. Naturalness preserved enhancement algorithm for non-uniform illumination images. IEEE Transactions on Image Processing, 22(9):3538&ndash;48, 2013.</span></p>
<p class="para-4"><span class="font-3">[3] Xueyang Fu, Delu Zeng, Yue Huang, Xiaoping Zhang, and Xinghao Ding. Aweighted variational model for simultaneous reflectance and illumination estimation. In Computer Vision and Pattern Recognition, pages 2782&ndash;2790, 2016.</span></p>
<p class="para-4"><span class="font-3">[4] Xiaojie Guo, Yu Li, and Haibin Ling. Lime: Low-light image enhancement via illumination map estimation. IEEE Transactions on Image Processing, 26(2):982&ndash;993, 2017.</span></p>
<p class="para-4"><span class="font-3">[5] Keda Ma, Kai Zeng, and Zhou Wang. Perceptual quality assessment for multi-exposure image fusion. IEEE Transactions on Image Processing, 24(11):3345, 2015.</span><span class="font-3">&nbsp;</span></p>
<p class="para-4"><span class="font-3">[6] Xutong Ren, Mading Li, Wen-Huang Cheng, and Jiaying Liu. Joint enhancement and denoising method via sequential decomposition. In Circuits and Systems (ISCAS), 2018 IEEE International Symposium on, pages 1&ndash;5. IEEE, 2018.</span></p>
-->
</div>
</div>
<script type="text/javascript" src="js/jquery.js"></script>
<script type="text/javascript" src="js/index.20180920212709.js"></script>
<script type="text/javascript">
var ver=RegExp(/Mozilla\/5\.0 \(Linux; .; Android ([\d.]+)/).exec(navigator.userAgent);if(ver&&parseFloat(ver[1])<5){document.getElementsByTagName('body')[0].className+=' whitespacefix';}
</script>
</body>
</html>
